{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eac6c79-153f-4f09-9ec4-9ac99ca87897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import *\n",
    "import utils\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import scprep, glob, sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c57d83-4020-4a36-a2f3-ebdd4ea53fcb",
   "metadata": {},
   "source": [
    "# inclusion/exclusion criteria workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2c9122-74f9-4f74-a3d3-5838dcb7ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After nBack exclusion: 7932 remaining\n"
     ]
    }
   ],
   "source": [
    "im=pd.read_csv(f'{NDA4}/abcd_imgincl01.txt',sep='\\t',low_memory=False)\n",
    "subjectkeys=im.subjectkey.unique()[1:]\n",
    "include_baseline  = np.zeros_like(subjectkeys)\n",
    "for i, s in enumerate(subjectkeys):\n",
    "    row = im[im['subjectkey']==s]\n",
    "    try:\n",
    "        base = row[row['eventname']==YEAR_CODES['baseline']]['imgincl_nback_include'].item()\n",
    "    except:\n",
    "        base=0\n",
    "    include_baseline[i]=base\n",
    "subject_df = pd.DataFrame({'subjectkey':subjectkeys,\n",
    "                           'imgincl_nback_include_baseline':include_baseline.astype(int),\n",
    "                          'passed_step1':include_baseline.astype(int)})\n",
    "print(f'After nBack exclusion: {np.sum(include_baseline.astype(int))} remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b9050a-c010-4658-9805-2bc41425f6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6354.0 remaining\n",
      "missing features=1712, excluding nback=3900, missing files=2769\n"
     ]
    }
   ],
   "source": [
    "# Make sure not missing social environment/contrasts/CBCL\n",
    "for FEAT in set((EXCLUDE_IF_MISSING + PREDICTORS_OF_INTEREST)):\n",
    "    v = utils.load_variables(subjectkeys, 'baseline', FEAT, PREDICTOR_TO_VARIABLE[FEAT])\n",
    "    subject_df[f'{FEAT}_baseline'] = v.astype(np.float64)\n",
    "\n",
    "has_baseline, has_2year=np.zeros_like(subjectkeys),np.zeros_like(subjectkeys)\n",
    "for i,s in enumerate(subjectkeys):\n",
    "    fns = glob.glob(f'{RELEASE4_CIFTI}/{s.replace('NDAR_','')}_baseline/nBack/*')\n",
    "    if len(fns)>0:\n",
    "        has_baseline[i] = 1\n",
    "    fns = glob.glob(f'{RELEASE4_CIFTI}/{s.replace('NDAR_','')}_2year/nBack/*')\n",
    "    if len(fns)>0:\n",
    "        has_2year[i] = 1\n",
    "        \n",
    "subject_df['has_baseline_contrasts']=has_baseline\n",
    "subject_df.set_index(\"subjectkey\", drop=True, inplace=True)\n",
    "subs_no_contrasts=subject_df[subject_df['has_baseline_contrasts']==0].index\n",
    "\n",
    "summed_values = subject_df.sum(skipna=False,axis=1).values\n",
    "subs_missing = subject_df.iloc[np.where(summed_values!=summed_values)[0]].index\n",
    "subs_no_nback = subject_df[subject_df['imgincl_nback_include_baseline']==0].index\n",
    "vec=np.ones_like(v)\n",
    "missing_features, missing_nback, missing_contrasts= 0,0,0\n",
    "for i,s in enumerate(subjectkeys):\n",
    "    if s in subs_missing:\n",
    "        vec[i]=0\n",
    "        missing_features+=1\n",
    "    if s in subs_no_nback:\n",
    "        vec[i]=0\n",
    "        missing_nback+=1\n",
    "    if s in subs_no_contrasts:\n",
    "        vec[i]=0\n",
    "        missing_contrasts+=1\n",
    "subject_df['passed_step2']=vec\n",
    "print(f'{np.sum(vec)} remaining') \n",
    "print(f'missing features={missing_features}, excluding nback={missing_nback}, missing files={missing_contrasts}')\n",
    "subject_df['has_2year_contrasts']=has_2year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e925f387-3aab-4318-ab52-dd1e8cb9cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After QC imaging data and 1 per family, 4732\n"
     ]
    }
   ],
   "source": [
    "subs_after_nimg_excl_baseline=utils.format_subjects(utils.select_brain_data_subjects('baseline', 'nBack_emotion_vs_neutface'))\n",
    "passed_step3=np.zeros_like(subjectkeys)\n",
    "for i,s in enumerate(subjectkeys):\n",
    "    if s in subs_after_nimg_excl_baseline:\n",
    "        passed_step3[i]=1\n",
    "subject_df['passed_step3']=passed_step3        \n",
    "print(f'After QC imaging data and 1 per family, {np.sum(passed_step3)}')\n",
    "# now do inclusion at baseline  timepoint overall\n",
    "subject_df['include_baseline_cohort'] = subject_df['passed_step3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71946f81-2a65-4d49-a569-0b057f733c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2371 included at 2-year\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "for F in ['cbcl_scr_syn_totprob_t', 'cbcl_scr_syn_internal_t', 'cbcl_scr_syn_external_t']:\n",
    "    v = utils.load_variables(subjectkeys, '2year', F,  PREDICTOR_TO_VARIABLE[F])\n",
    "    v = np.where(v>0,1,0) # does it exist, if not, 0\n",
    "    vals.append(v)\n",
    "vals=np.array(vals)\n",
    "\n",
    "has_2year=np.zeros_like(subjectkeys)\n",
    "summed=np.sum(np.array(vals), axis=0)\n",
    "has_2year[np.where(summed==3)[0]]=1\n",
    "im_incl = utils.load_variables(subjectkeys, '2year', [\"imgincl_nback_include\"],  'imgincl')\n",
    "has_2year = has_2year*im_incl\n",
    "subject_df['passed_step4']=has_2year\n",
    "subject_df['include_longitudinal_cohort'] = subject_df['passed_step3'] + subject_df['passed_step4'] + subject_df['has_2year_contrasts']\n",
    "subject_df['include_longitudinal_cohort'] = np.array([s == 3 for s in subject_df['include_longitudinal_cohort'].values]).astype(int)\n",
    "print(f'{np.sum(subject_df['include_longitudinal_cohort'].values)} included at 2-year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c01e7d-7a6a-4c5d-a423-34f39287b61a",
   "metadata": {},
   "source": [
    "# comparison of subjects included vs not included, who have nback imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b27a56f-d198-46fd-bc0b-1f682a1e95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for subjects who were / werent included \n",
    "filename=f'{PROJECT_DIR}/data/overall_subjects.csv'\n",
    "if os.path.exists(filename):\n",
    "    df1=pd.read_csv(filename)\n",
    "else:\n",
    "    # subjects who had enback data but were then dropped later on in the process\n",
    "    df1 = subject_df[subject_df['passed_step1']==1]\n",
    "    df1 = df1[['include_longitudinal_cohort','include_baseline_cohort']]\n",
    "    \n",
    "    for F,V in PREDICTOR_TO_VARIABLE.items():\n",
    "        v = utils.load_variables(df1.index, 'baseline', F, V)\n",
    "        try:\n",
    "            df1[f'{F}'] = v.astype(np.float64)\n",
    "        except: \n",
    "            df1[f'{F}'] = v\n",
    "df1=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dff69bc-fb1a-4d2b-b0fb-5b77aedc5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['cbcl_scr_syn_external_t', 'cbcl_scr_syn_internal_t', 'cbcl_scr_syn_totprob_t', 'crpbi_y_ss_caregiver',\n",
    " 'fes_y_ss_fc', 'nsc_p_ss_mean_3_items',  'race_ethnicity', 'reshist_addr1_adi_perc',\n",
    "'demo_prnt_ed_v2', 'demo_comb_income_v2']\n",
    "x_cols_z=[f'{x}_z' for x in x_cols]\n",
    "\n",
    "for x in x_cols:\n",
    "    v = df1[x].values\n",
    "    if v.dtype =='O': \n",
    "        df1.loc[df1.index, f'{x}_z'] = df1[x].values\n",
    "    else: # dont try to normalize strings\n",
    "        df1.loc[df1.index, f'{x}_z']=scipy.stats.zscore(v, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d9c44a-3f1b-4fcc-afe4-d5e5140f918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excls = df1.dropna()\n",
    "for x in x_cols:\n",
    "    v = df_excls[x].values\n",
    "    if v.dtype =='O': \n",
    "        df_excls.loc[df1.index, f'{x}_z'] = df1[x].values\n",
    "    else: # dont try to normalize strings\n",
    "        df_excls.loc[df_excls.index, f'{x}_z']=scipy.stats.zscore(v)\n",
    "df1.loc[df1.index,'include_baseline_cohort']=df1['include_baseline_cohort'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdbb4218-bac4-43d9-90f8-9b9418e6436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691050\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>include_baseline_cohort</td> <th>  No. Observations:  </th>  <td>  6770</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>Logit</td>          <th>  Df Residuals:      </th>  <td>  6760</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                    <td>MLE</td>           <th>  Df Model:          </th>  <td>     9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>               <td>Tue, 13 Aug 2024</td>     <th>  Pseudo R-squ.:     </th>  <td>-0.1149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                   <td>14:09:20</td>         <th>  Log-Likelihood:    </th> <td> -4678.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>                <td>True</td>           <th>  LL-Null:           </th> <td> -4196.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>nonrobust</td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_external_t_z</th> <td>   -0.0231</td> <td>    0.048</td> <td>   -0.480</td> <td> 0.631</td> <td>   -0.118</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_internal_t_z</th> <td>    0.0600</td> <td>    0.048</td> <td>    1.250</td> <td> 0.211</td> <td>   -0.034</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_totprob_t_z</th>  <td>   -0.0252</td> <td>    0.071</td> <td>   -0.354</td> <td> 0.723</td> <td>   -0.165</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crpbi_y_ss_caregiver_z</th>    <td>   -0.0231</td> <td>    0.025</td> <td>   -0.919</td> <td> 0.358</td> <td>   -0.073</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fes_y_ss_fc_z</th>             <td>    0.0039</td> <td>    0.026</td> <td>    0.154</td> <td> 0.877</td> <td>   -0.046</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nsc_p_ss_mean_3_items_z</th>   <td>   -0.0567</td> <td>    0.026</td> <td>   -2.171</td> <td> 0.030</td> <td>   -0.108</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_ethnicity_z</th>          <td>    0.0310</td> <td>    0.025</td> <td>    1.258</td> <td> 0.209</td> <td>   -0.017</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reshist_addr1_adi_perc_z</th>  <td>    0.0639</td> <td>    0.026</td> <td>    2.458</td> <td> 0.014</td> <td>    0.013</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_prnt_ed_v2_z</th>         <td>   -0.0283</td> <td>    0.026</td> <td>   -1.078</td> <td> 0.281</td> <td>   -0.080</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_comb_income_v2_z</th>     <td>    0.0409</td> <td>    0.025</td> <td>    1.655</td> <td> 0.098</td> <td>   -0.008</td> <td>    0.089</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                 & include\\_baseline\\_cohort & \\textbf{  No. Observations:  } &     6770    \\\\\n",
       "\\textbf{Model:}                         &           Logit           & \\textbf{  Df Residuals:      } &     6760    \\\\\n",
       "\\textbf{Method:}                        &            MLE            & \\textbf{  Df Model:          } &        9    \\\\\n",
       "\\textbf{Date:}                          &      Tue, 13 Aug 2024     & \\textbf{  Pseudo R-squ.:     } &  -0.1149    \\\\\n",
       "\\textbf{Time:}                          &          14:09:20         & \\textbf{  Log-Likelihood:    } &   -4678.4   \\\\\n",
       "\\textbf{converged:}                     &            True           & \\textbf{  LL-Null:           } &   -4196.3   \\\\\n",
       "\\textbf{Covariance Type:}               &         nonrobust         & \\textbf{  LLR p-value:       } &    1.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{cbcl\\_scr\\_syn\\_external\\_t\\_z} &      -0.0231  &        0.048     &    -0.480  &         0.631        &       -0.118    &        0.071     \\\\\n",
       "\\textbf{cbcl\\_scr\\_syn\\_internal\\_t\\_z} &       0.0600  &        0.048     &     1.250  &         0.211        &       -0.034    &        0.154     \\\\\n",
       "\\textbf{cbcl\\_scr\\_syn\\_totprob\\_t\\_z}  &      -0.0252  &        0.071     &    -0.354  &         0.723        &       -0.165    &        0.114     \\\\\n",
       "\\textbf{crpbi\\_y\\_ss\\_caregiver\\_z}     &      -0.0231  &        0.025     &    -0.919  &         0.358        &       -0.073    &        0.026     \\\\\n",
       "\\textbf{fes\\_y\\_ss\\_fc\\_z}              &       0.0039  &        0.026     &     0.154  &         0.877        &       -0.046    &        0.054     \\\\\n",
       "\\textbf{nsc\\_p\\_ss\\_mean\\_3\\_items\\_z}  &      -0.0567  &        0.026     &    -2.171  &         0.030        &       -0.108    &       -0.006     \\\\\n",
       "\\textbf{race\\_ethnicity\\_z}             &       0.0310  &        0.025     &     1.258  &         0.209        &       -0.017    &        0.079     \\\\\n",
       "\\textbf{reshist\\_addr1\\_adi\\_perc\\_z}   &       0.0639  &        0.026     &     2.458  &         0.014        &        0.013    &        0.115     \\\\\n",
       "\\textbf{demo\\_prnt\\_ed\\_v2\\_z}          &      -0.0283  &        0.026     &    -1.078  &         0.281        &       -0.080    &        0.023     \\\\\n",
       "\\textbf{demo\\_comb\\_income\\_v2\\_z}      &       0.0409  &        0.025     &     1.655  &         0.098        &       -0.008    &        0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              Logit Regression Results                             \n",
       "===================================================================================\n",
       "Dep. Variable:     include_baseline_cohort   No. Observations:                 6770\n",
       "Model:                               Logit   Df Residuals:                     6760\n",
       "Method:                                MLE   Df Model:                            9\n",
       "Date:                     Tue, 13 Aug 2024   Pseudo R-squ.:                 -0.1149\n",
       "Time:                             14:09:20   Log-Likelihood:                -4678.4\n",
       "converged:                            True   LL-Null:                       -4196.3\n",
       "Covariance Type:                 nonrobust   LLR p-value:                     1.000\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "cbcl_scr_syn_external_t_z    -0.0231      0.048     -0.480      0.631      -0.118       0.071\n",
       "cbcl_scr_syn_internal_t_z     0.0600      0.048      1.250      0.211      -0.034       0.154\n",
       "cbcl_scr_syn_totprob_t_z     -0.0252      0.071     -0.354      0.723      -0.165       0.114\n",
       "crpbi_y_ss_caregiver_z       -0.0231      0.025     -0.919      0.358      -0.073       0.026\n",
       "fes_y_ss_fc_z                 0.0039      0.026      0.154      0.877      -0.046       0.054\n",
       "nsc_p_ss_mean_3_items_z      -0.0567      0.026     -2.171      0.030      -0.108      -0.006\n",
       "race_ethnicity_z              0.0310      0.025      1.258      0.209      -0.017       0.079\n",
       "reshist_addr1_adi_perc_z      0.0639      0.026      2.458      0.014       0.013       0.115\n",
       "demo_prnt_ed_v2_z            -0.0283      0.026     -1.078      0.281      -0.080       0.023\n",
       "demo_comb_income_v2_z         0.0409      0.025      1.655      0.098      -0.008       0.089\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression for inclusion at baseline\n",
    "logit_mod = sm.Logit(exog=df1[x_cols_z], endog=df1['include_baseline_cohort'])\n",
    "model_res = logit_mod.fit()\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5996fe37-a68b-41f2-815b-3ac7b154fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692139\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>include_longitudinal_cohort</td> <th>  No. Observations:  </th>  <td>  6770</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                      <td>Logit</td>            <th>  Df Residuals:      </th>  <td>  6760</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                      <td>MLE</td>             <th>  Df Model:          </th>  <td>     9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                 <td>Tue, 13 Aug 2024</td>       <th>  Pseudo R-squ.:     </th> <td>-0.04947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                     <td>14:09:34</td>           <th>  Log-Likelihood:    </th> <td> -4685.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>                  <td>True</td>             <th>  LL-Null:           </th> <td> -4464.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>nonrobust</td>          <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_external_t_z</th> <td>   -0.0851</td> <td>    0.048</td> <td>   -1.767</td> <td> 0.077</td> <td>   -0.180</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_internal_t_z</th> <td>    0.0460</td> <td>    0.048</td> <td>    0.959</td> <td> 0.337</td> <td>   -0.048</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cbcl_scr_syn_totprob_t_z</th>  <td>    0.0424</td> <td>    0.071</td> <td>    0.596</td> <td> 0.551</td> <td>   -0.097</td> <td>    0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crpbi_y_ss_caregiver_z</th>    <td>    0.0004</td> <td>    0.025</td> <td>    0.015</td> <td> 0.988</td> <td>   -0.049</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fes_y_ss_fc_z</th>             <td>    0.0214</td> <td>    0.025</td> <td>    0.841</td> <td> 0.400</td> <td>   -0.029</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nsc_p_ss_mean_3_items_z</th>   <td>    0.0065</td> <td>    0.026</td> <td>    0.250</td> <td> 0.802</td> <td>   -0.045</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_ethnicity_z</th>          <td>   -0.0535</td> <td>    0.025</td> <td>   -2.171</td> <td> 0.030</td> <td>   -0.102</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reshist_addr1_adi_perc_z</th>  <td>    0.0365</td> <td>    0.026</td> <td>    1.408</td> <td> 0.159</td> <td>   -0.014</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_prnt_ed_v2_z</th>         <td>   -0.0029</td> <td>    0.025</td> <td>   -0.119</td> <td> 0.905</td> <td>   -0.051</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_comb_income_v2_z</th>     <td>   -0.0022</td> <td>    0.025</td> <td>   -0.089</td> <td> 0.929</td> <td>   -0.050</td> <td>    0.046</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                 & include\\_longitudinal\\_cohort & \\textbf{  No. Observations:  } &     6770    \\\\\n",
       "\\textbf{Model:}                         &             Logit             & \\textbf{  Df Residuals:      } &     6760    \\\\\n",
       "\\textbf{Method:}                        &              MLE              & \\textbf{  Df Model:          } &        9    \\\\\n",
       "\\textbf{Date:}                          &        Tue, 13 Aug 2024       & \\textbf{  Pseudo R-squ.:     } &  -0.04947   \\\\\n",
       "\\textbf{Time:}                          &            14:09:34           & \\textbf{  Log-Likelihood:    } &   -4685.8   \\\\\n",
       "\\textbf{converged:}                     &              True             & \\textbf{  LL-Null:           } &   -4464.9   \\\\\n",
       "\\textbf{Covariance Type:}               &           nonrobust           & \\textbf{  LLR p-value:       } &    1.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{cbcl\\_scr\\_syn\\_external\\_t\\_z} &      -0.0851  &        0.048     &    -1.767  &         0.077        &       -0.180    &        0.009     \\\\\n",
       "\\textbf{cbcl\\_scr\\_syn\\_internal\\_t\\_z} &       0.0460  &        0.048     &     0.959  &         0.337        &       -0.048    &        0.140     \\\\\n",
       "\\textbf{cbcl\\_scr\\_syn\\_totprob\\_t\\_z}  &       0.0424  &        0.071     &     0.596  &         0.551        &       -0.097    &        0.182     \\\\\n",
       "\\textbf{crpbi\\_y\\_ss\\_caregiver\\_z}     &       0.0004  &        0.025     &     0.015  &         0.988        &       -0.049    &        0.050     \\\\\n",
       "\\textbf{fes\\_y\\_ss\\_fc\\_z}              &       0.0214  &        0.025     &     0.841  &         0.400        &       -0.029    &        0.071     \\\\\n",
       "\\textbf{nsc\\_p\\_ss\\_mean\\_3\\_items\\_z}  &       0.0065  &        0.026     &     0.250  &         0.802        &       -0.045    &        0.058     \\\\\n",
       "\\textbf{race\\_ethnicity\\_z}             &      -0.0535  &        0.025     &    -2.171  &         0.030        &       -0.102    &       -0.005     \\\\\n",
       "\\textbf{reshist\\_addr1\\_adi\\_perc\\_z}   &       0.0365  &        0.026     &     1.408  &         0.159        &       -0.014    &        0.087     \\\\\n",
       "\\textbf{demo\\_prnt\\_ed\\_v2\\_z}          &      -0.0029  &        0.025     &    -0.119  &         0.905        &       -0.051    &        0.045     \\\\\n",
       "\\textbf{demo\\_comb\\_income\\_v2\\_z}      &      -0.0022  &        0.025     &    -0.089  &         0.929        &       -0.050    &        0.046     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                Logit Regression Results                               \n",
       "=======================================================================================\n",
       "Dep. Variable:     include_longitudinal_cohort   No. Observations:                 6770\n",
       "Model:                                   Logit   Df Residuals:                     6760\n",
       "Method:                                    MLE   Df Model:                            9\n",
       "Date:                         Tue, 13 Aug 2024   Pseudo R-squ.:                -0.04947\n",
       "Time:                                 14:09:34   Log-Likelihood:                -4685.8\n",
       "converged:                                True   LL-Null:                       -4464.9\n",
       "Covariance Type:                     nonrobust   LLR p-value:                     1.000\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "cbcl_scr_syn_external_t_z    -0.0851      0.048     -1.767      0.077      -0.180       0.009\n",
       "cbcl_scr_syn_internal_t_z     0.0460      0.048      0.959      0.337      -0.048       0.140\n",
       "cbcl_scr_syn_totprob_t_z      0.0424      0.071      0.596      0.551      -0.097       0.182\n",
       "crpbi_y_ss_caregiver_z        0.0004      0.025      0.015      0.988      -0.049       0.050\n",
       "fes_y_ss_fc_z                 0.0214      0.025      0.841      0.400      -0.029       0.071\n",
       "nsc_p_ss_mean_3_items_z       0.0065      0.026      0.250      0.802      -0.045       0.058\n",
       "race_ethnicity_z             -0.0535      0.025     -2.171      0.030      -0.102      -0.005\n",
       "reshist_addr1_adi_perc_z      0.0365      0.026      1.408      0.159      -0.014       0.087\n",
       "demo_prnt_ed_v2_z            -0.0029      0.025     -0.119      0.905      -0.051       0.045\n",
       "demo_comb_income_v2_z        -0.0022      0.025     -0.089      0.929      -0.050       0.046\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression for inclusion at 2 year\n",
    "logit_mod = sm.Logit(exog=df1[x_cols_z], endog=df1['include_longitudinal_cohort'])\n",
    "model_res = logit_mod.fit()\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a6164-a272-4fd1-a835-07bcf0073d5f",
   "metadata": {},
   "source": [
    "# sample demographics\n",
    "\n",
    "demo_comb_income_v2 (pdem02)<br>\n",
    "``1= Less than $5,000; 2=$5,000 through $11,999; 3=$12,000 through $15,999; \n",
    "4=$16,000 through $24,999; 5=$25,000 through $34,999; 6=$35,000 through $49,999; \n",
    "7=$50,000 through $74,999; 8= $75,000 through $99,999; 9=$100,000 through $199,999; \n",
    "10=$200,000 and greater. 999 = Don't know ``<br> \n",
    "**Recoded:**\n",
    "1 = < 50K (<6)<br> \n",
    "2 = < 100K (7,8)<br>\n",
    "3 = > 100K (9, 10)<br> \n",
    "4 = Unknown 777/999\n",
    "<br><br>\n",
    "demo_prnt_ed_v2 (pdem02)<br> \n",
    "``0 = Never attended/Kindergarten only Nunca asist√É¬≠/Kinder solamente ; 1 = 1st grade \n",
    "2 = 2nd grade 3 = 3rd grade 4 = 4th grade 5 = 5th grade 6 = 6th grade 7 = 7th grade \n",
    "8 = 8th grade ; 9 = 9th grade ; 10 = 10th grade  ; 11 = 11th grade  ; 12 = 12th grade; \n",
    "13 = High school graduate  ; 14 = GED  ; 15 = Some college; 16 = Associate degree: Occupational; \n",
    "17 = Associate degree: Academic Program  ; 18 = Bachelor's degree (ex. BA; \n",
    "19 = Master's degree (ex. MA; \n",
    "20 = Professional School degree (ex. MD; \n",
    "21 = Doctoral degree (ex. PhD; 777 = Refused to answer``<br>\n",
    "**Recoded**<br> \n",
    "1 = < HS (< 13)<br> \n",
    "2 = HS Diploma / GED (13,14)<br> \n",
    "3 = Some college (15,16,17)<br> \n",
    "4 = Bachelor (18)<br> \n",
    "5 = Post graduate degree (19,20,21)<br> \n",
    "6 = Unknown (777,999)<br> \n",
    "<br> \n",
    "race_ethnicity (acspw03)<br> \n",
    "``1 = White; 2 = Black; 3 = Hispanic; 4 = Asian; 5 = Other``<br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43ecab6d-c464-4b7f-8142-431eeb993ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2799978/2816889248.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp.loc[tmp.index,'recoded_income']=recoded_inc\n",
      "/tmp/ipykernel_2799978/2816889248.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp.loc[tmp.index,'recoded_edu']=recoded_edu\n"
     ]
    }
   ],
   "source": [
    "subs_included=pd.read_csv(f'{PROJECT_DIR}/data/subjects_included.csv')\n",
    "df1=pd.read_csv(f'{PROJECT_DIR}/data/overall_subjects.csv')\n",
    "target_cols = ['subjectkey','include_longitudinal_cohort','include_baseline_cohort','interview_age','race_ethnicity','sex','demo_comb_income_v2','demo_prnt_ed_v2','site_id_l']\n",
    "df_baseline = df1[df1['include_baseline_cohort']==1]#[target_cols] \n",
    "df_longit = df1[df1['include_longitudinal_cohort']==1][target_cols] \n",
    "MERGE = lambda d1, d2 : {**d1, **d2}\n",
    "recoded_income = {1:1,2:1, 3:1, 4:1, 5:1, 6:1, 7:2, 8:2, 9:3, 10:3, 777:0,999:0}\n",
    "recoded_educat = MERGE({i: 1 for i in range(13)}, {13:2, 14:2, 15:3, 16:3, 17:3, 18:4, 19:5, 20:5, 21:5, 777:6, 999:6})\n",
    "for tmp in [df_baseline, df_longit]:\n",
    "    vals = tmp['demo_comb_income_v2'].values                                           \n",
    "    recoded_inc = np.array([recoded_income[i] for i in vals])\n",
    "    vals = tmp['demo_prnt_ed_v2'].values                                           \n",
    "    recoded_edu = np.array([recoded_educat[i] for i in vals])\n",
    "    tmp.loc[tmp.index,'recoded_income']=recoded_inc\n",
    "    tmp.loc[tmp.index,'recoded_edu']=recoded_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913ced6-aa33-4e40-b714-cdb3fa59ff44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
